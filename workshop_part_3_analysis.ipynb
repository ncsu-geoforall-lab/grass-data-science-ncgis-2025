{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: From Viewshed to Viewscape \n",
    "\n",
    "In the third part, we will demonstrate the use of GRASS for a small viewshed case study.\n",
    "The goal is to **analyze the area a driver would see from a road**.\n",
    "This notebook can be run only after notebook Part 2 was executed.\n",
    "\n",
    "Topics covered:\n",
    " * raster algebra ([r.mapcalc](https://grass.osgeo.org/grass-stable/manuals/r.mapcalc.html))\n",
    " * raster mask ([r.mask](https://grass.osgeo.org/grass-stable/manuals/r.mask.html))\n",
    " * raster as a numpy array ([grass.script.array](https://grass.osgeo.org/grass-stable/manuals/libpython/script.html#module-script.array))\n",
    " * statistics, data wrangling, and plotting with GRASS directly and together with pandas and seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Python libraries. (This may be be skipped in the Google Colab notebook where we already did this  at the beginning of the single, long notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python standard library and IPython packages we need.\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Ask GRASS where its Python packages are.\n",
    "sys.path.append(\n",
    "    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n",
    ")\n",
    "\n",
    "# Import the GRASS packages we need.\n",
    "import grass.script as gs\n",
    "import grass.jupyter as gj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook (Part 1) we created new project *dix_park*. This automatically created new default mapset (subproject) _PERMANENT_ where we then imported our base data. Now it's time to create a new mapset for our viewshed analysis, we will name it _viewshed_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grass.experimental import require_create_ensure_mapset\n",
    "\n",
    "# Create mapset if it does not exist and continue if it already exists.\n",
    "# (By deafult, the function requires the mapset to exist.)\n",
    "require_create_ensure_mapset(\"dix_park/analysis\", ensure=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a new session in the mapset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start GRASS session\n",
    "session = gj.init(\"dix_park/analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing and Accessing Data Across Mapsets\n",
    "\n",
    "A project consists of one or more mapsets which facilitate data organization and protection. Mapsets act as subprojects or namespaces.\n",
    "\n",
    "Using _g.mapsets_ with the _l_ flag, we can see that our current project has now these three mapsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.mapsets\", flags=\"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we can see data in our current mapset and in the default mapset called PERMANENT. We can see that by using _g.mapsets_ with the _l_ flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.mapsets\", flags=\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we see the data in PERMANENT and they are available for reading, creating or editing data is only possible in the current mapset, protecting the data from unintentional modifications.\n",
    "\n",
    "The _g.list_ tools can list the data we currently see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.list\", type=\"raster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the list of data suggests, the data can be accessed without specifying the mapset. Using _r.info_, we show metadata of a raster in the PERMANENT mapset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.info\", map=\"dsm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When needed, mapset name can be used explicitly with name-at-mapset syntax written like `name@mapset`. This is also know as the _full name_ or _fully qualified name_ within a project. Full names are useful when we have the same or similar names for data in multiple mapsets. In our case, we don't have to use mapset name explicilty to make that distinction, but we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.info\", map=\"dsm@PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the data using the full names by adding the _m_ flag to the _g.list_ call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.list\", type=\"raster\", flags=\"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the full name, we can access data in any mapset (within the project). Again, this data is accessible for reading, so we can, for example, get metadata of a raster we created before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.info\", map=\"viewshed_10@viewshed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid using the full name for data in specific mapset or mapsets by adding the mapset to the list called _search path_ which is a list of mapsets where data is searched for when the name is used without a mapset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.mapsets\", mapset=\"viewshed\", operation=\"add\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the _g.mapsets_ tool with _p_ flag tells us the three, not two, mapsets which are on our search path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.mapsets\", flags=\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we list data, we see data from the there mapsets on our search path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.list\", type=\"raster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative viewshed\n",
    "We can compute the cumulative viewshed, which aggregates viewsheds from multiple viewpoints. In this way you can e.g., identify the most frequently visible areas from the road.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the computation, we set the computational region to the raster we used to compute the viewsheds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.region\", region=\"umstead_drive_region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g.list pattern=\"viewshed_[0-9]+\" type=\"raster\" -e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = gs.list_strings(type=\"raster\", pattern=\"viewshed_[0-9]+\", flag=\"e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our viewshed rasters are binary (0 invisible, 1 visible), we will use r.series method *sum*. Then we replace zeros with no data using r.null and set a new color ramp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative viewshed\n",
    "gs.run_command(\"r.series\", input=maps, output=\"cumulative_viewshed\", method=\"sum\")\n",
    "gs.run_command(\"r.null\", map=\"cumulative_viewshed\", setnull=0)\n",
    "gs.run_command(\"r.colors\", map=\"cumulative_viewshed\", color=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_map = gj.InteractiveMap()\n",
    "cumulative_map.add_raster(\"cumulative_viewshed\", opacity=0.8)\n",
    "cumulative_map.add_vector(\"umstead_drive\")\n",
    "cumulative_map.add_layer_control(position=\"bottomright\")\n",
    "cumulative_map.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a 3D rendering with draped cumulative viewshed over the DSM (this won't work in Google Colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map3d = gj.Map3D()\n",
    "map3d.render(\n",
    "    elevation_map=\"dsm\",\n",
    "    resolution_fine=1,\n",
    "    color_map=\"cumulative_viewshed\",\n",
    "    vline=\"umstead_drive\",\n",
    "    vline_width=3,\n",
    "    vline_color=\"white\",\n",
    "    light_brightness=50,\n",
    "    position=[0.4, 0.8],\n",
    "    height=3000,\n",
    "    perspective=10,\n",
    ")\n",
    "map3d.overlay.d_legend(\n",
    "    raster=\"cumulative_viewshed\", at=(0, 30, 1, 7), use=[1, 2, 3, 4, 5, 6], flags=\"fb\"\n",
    ")\n",
    "map3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of Continuous Variable\n",
    "Now let's compute Excess Green Index (ExGI, [Woebbecke et al.](https://elibrary.asabe.org/abstract.asp?aid=27838)) from orthophoto and analyze its distribution within the visible area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break down the RGB image into RGB components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.rgb\", input=\"ortho\", red=\"red\", green=\"green\", blue=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute ExGI using raster algebra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.mapcalc(\"exgi = (2.0 * green - red - blue)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_map = gj.Map()\n",
    "green_map.d_rast(map=\"exgi\")\n",
    "green_map.d_legend(raster=\"exgi\", flags=\"t\")\n",
    "green_map.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.relief\", input=\"ground\", output=\"relief\")\n",
    "\n",
    "green_map = gj.Map()\n",
    "green_map.d_shade(shade=\"relief\", color=\"exgi\", brighten=50)\n",
    "green_map.d_legend(raster=\"exgi\", flags=\"t\")\n",
    "green_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use mask, to limit the analysis only to the data in the visible area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mask\", raster=\"cumulative_viewshed\")\n",
    "data = gs.parse_command(\"r.univar\", map=\"exgi\", flags=\"g\")\n",
    "print(\n",
    "    f\"Average ExGI of visible cells: {float(data['mean']):.2f} ± {float(data['stddev']):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_map = gj.Map()\n",
    "green_map.d_rast(map=\"exgi\")\n",
    "green_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the histogram of visible ExGI using d.histogram (we are still using the mask):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo = gj.Map(width=800, height=400)\n",
    "histo.d_histogram(map=\"exgi\", nsteps=50)\n",
    "histo.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low and missing bars are suspitious as we expepect the values to be continuous. However, when we look at the report about values in one of the underlying rasters, using _r.report_, we see that it is not continous either. This is given by spectral resolution of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.report\", map=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also easy to use the results as a numpy array and then use other Python libraries to analyze the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import grass.script.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exgi = gs.array.array(mapname=\"exgi\", null=\"nan\")\n",
    "exgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.histplot(exgi.ravel(), kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remove the mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our excercise, we will create categorical data from the ExGI raster by a simple threshold with raster algebra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mapcalc\", expression=\"vegetated = if(exgi > 20, 1, 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To label the categories, we will use _r.category_ and will provide it with labeling rules as standard text input (_stdin_), using the _write_command_ function with parameter _rules_ set to `\"-\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = \"\"\"\n",
    "1:vegetated\n",
    "0:not vegetated\n",
    "\"\"\"\n",
    "gs.write_command(\n",
    "    \"r.category\", map=\"vegetated\", separator=\":\", rules=\"-\", stdin=rules\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also assign colors to each category in a similar way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = \"\"\"\n",
    "1 #9ed528\n",
    "0 #61709c\n",
    "\"\"\"\n",
    "gs.write_command(\n",
    "    \"r.colors\", map=\"vegetated\", rules=\"-\", stdin=rules\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are not using DSM for our classification of areas which are vegetated and not vegetated, let's use DSM for the relief background as a check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.relief\", input=\"dsm\", output=\"dsm_relief\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DSM-based relief and Umstead Drive for context, show the vegetation map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_map = gj.Map()\n",
    "green_map.d_shade(shade=\"dsm_relief\", color=\"vegetated\", brighten=50)\n",
    "green_map.d_vect(map=\"umstead_drive\", width=3, color=\"white\")\n",
    "green_map.d_legend(raster=\"vegetated\", flags=\"fbc\", at=(60,80,70,75), title=\"ExGI-based Vegetation\")\n",
    "green_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the trees are identified as not vegetated. That's unexpected even for our naive threshold approach. However, when we look at the orthophoto which is actually our source data, it is clear that most of the trees appear brown on this leaf-off orthophoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_map = gj.Map(use_region=True)\n",
    "green_map.d_rast(map=\"ortho\")\n",
    "green_map.d_vect(map=\"umstead_drive\", width=3, color=\"white\")\n",
    "green_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With information about vegetation presence ready, let's get the specific number of cells in each of our categories (classes). (We are using number of cells, but we could also use area instead.) We will use _r.stats_ to give us these counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gs.read_command(\"r.stats\", input=\"vegetated\", flags=\"cnl\", separator=\",\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statistics is for our whole study area defined by the computational region. To do our actual analysis, we want to limit that to a viewshed, using _r.mask_. We will start by limiting the analysis to the cumulative viewshed we created. To get the data from _r.stats_ into Python, we could string basic manipulation such as `line.split(\",\")`, but here we will use _csv.DictReader_ from standard Python library because that's more robust and readable. We don't do anything with the data yet, we just print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mask\", raster=\"cumulative_viewshed\")\n",
    "data = gs.read_command(\"r.stats\", input=\"vegetated\", flags=\"cnl\", separator=\",\")\n",
    "\n",
    "import csv\n",
    "import io\n",
    "\n",
    "reader = csv.DictReader(\n",
    "    io.StringIO(data), delimiter=\",\", fieldnames=[\"category\", \"label\", \"count\"]\n",
    ")\n",
    "for row in reader:\n",
    "    print(row)\n",
    "\n",
    "gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's collect the number of vegetated and non vegetated cells for each of the viewsheds. This adds another for loop. We will use _r.mask_ to limit the counting done by _r.stats_ just to one viewshed. We will create a new table as a list where each row is a dictionary with viewshed name and counts of cells of each kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for viewshed in maps:\n",
    "    gs.run_command(\"r.mask\", raster=viewshed, maskcats=\"1\")\n",
    "    data = gs.read_command(\"r.stats\", input=\"vegetated\", flags=\"cnl\", separator=\",\")\n",
    "    reader = csv.DictReader(\n",
    "        io.StringIO(data), delimiter=\",\", fieldnames=[\"category\", \"label\", \"count\"]\n",
    "    )\n",
    "    result_row = {}\n",
    "    # Store the viewshed name.\n",
    "    result_row[\"viewshed\"] = viewshed\n",
    "    for row in reader:\n",
    "        # Store count under the corresponding label.\n",
    "        result_row[row[\"label\"]] = int(row[\"count\"])\n",
    "    result.append(result_row)\n",
    "    gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, we convert the table to a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Seaborn prefers melted DataFrame where rows are measurements,\n",
    "# category labels are variables, and only one column with counts.\n",
    "# The resulting DataFrame has only 3 columns, but 2x more rows. \n",
    "df_melted = df.melt(id_vars=[\"viewshed\"], var_name=\"type\", value_name=\"count\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    data=df_melted,\n",
    "    x=\"viewshed\",\n",
    "    y=\"count\",\n",
    "    hue=\"type\",\n",
    "    palette=[\"#61709c\", \"#9ed528\"],\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Viewshed\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Comparison of Vegetated and Non-Vegetated Areas in Each Viewshed\")\n",
    "plt.legend(title=\"ExGI-based Vegetation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we are interested in places where the traveler sees most green vegetation, so we will filter viewsheds where vegetated area is higher or nearly equal to non-vegetated area. We will set our threshold for nearly equal to 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "# pandas expression for our condition\n",
    "selected_viewsheds = df[\n",
    "    (df[\"vegetated\"] >= df[\"not vegetated\"]) |\n",
    "    (abs(df[\"vegetated\"] - df[\"not vegetated\"]) /\n",
    "     (df[\"vegetated\"] + df[\"not vegetated\"]) <= threshold\n",
    "    )\n",
    "]\n",
    "selected_viewsheds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of viewsheds, we can look where there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_map = gj.Map(use_region=True)\n",
    "green_map.d_rast(map=\"ortho\")\n",
    "green_map.d_vect(map=\"umstead_drive\", width=3, color=\"white\")\n",
    "for name in selected_viewsheds[\"viewshed\"]:\n",
    "    green_map.d_rast(map=name, values=1)\n",
    "green_map.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
